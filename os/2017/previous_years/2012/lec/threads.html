<html>
<head>
<title>System Calls and Threads</title>
</head>
<body>

<h1>System Calls and Threads</h1>

<h2>Outline</h2>
<ul>
<li>System Calls: fork, exec, exit, wait, open, read, write, close, kill, signal, pipe
<li>Case Study: Unix/xv6 shell (simplified)
<li>Kernel-level Threads
<li>User-level Threads
<li>Intro to Concurrency and Locks
</ul>

<h2>System Calls</h2>
<ul>
	<li>"Kernel functions" that perform privileged operations on behalf
of the process. As an OS designer, one of the goals is to minimize the
system call interface.</li>

<li>UNIX's <code>fork()</code> and <code>exec()</code>
versus Windows' <code>CreateProcess()</code></li>

<li>pipe() system call</li>

<li>UNIX process inheritance and file sharing</li>
</ul>

<h2>Case study: Unix/xv6 shell (simplified)</h2>

<ul>
<li>provides an interactive command execution and programming language
<li>typically handles login session, runs other processes
<li>look at some simple examples of shell operations, how they
    use different OS abstractions, and how those abstractions
    fit together.
    See <a href="../bib/ritchie74unix.pdf">Unix paper</a>
    if you are unfamiliar with the shell.
<li>Basic structure:
<pre>
	while (1) {
	    write (1, "$ ", 2);			// 1 = STDOUT_FILENO
	    readcommand (0, command, args);	// parse user input, 0 = STDIN_FILENO
	    if ((pid = fork ()) == 0) {		// child?
		exec (command, args, 0);
	    } else if (pid > 0) {		// parent?
		wait (0);			// wait for child to terminate
	    } else {
		perror ("Failed to fork\n");
	    }
	}
</pre>
<li>system calls: <code>read</code>, <code>write</code>,
	<code>fork</code>, <code>exec</code>, <code>wait</code>.
    conventions: -1 return value signals error,
    error code stored in <code>errno</code>,
    <code>perror</code> prints out a descriptive error
    message based on <code>errno</code>.
<li>What's the shell doing?
    fork, exec, wait: process diagram
    (PID, address space -- memory of the process, parent links).
    fork returns twice, in some sense!
<p>The split of process creation into fork and exec
    turns out to have been an inspired choice, though that
    might not have been clear at the time; see today's
    <a href="../bib/ritchie79evolution.pdf">assigned paper</a>.
<li>why call "wait"?  to wait for the child to terminate and collect
    its exit status.  (if child finishes, child becomes a zombie until
    parent calls wait.)

<li>Example:
<pre>
	$ ls
</pre>
<li>how does ls know which directory to look at?
<li>how does it know what to do with its output?
<li>I/O: process has file descriptors, numbered starting from 0.
<li>system calls: open, read, write, close

<li>numbering conventions:
<ul>
<li>file descriptor 0 for input (e.g., keyboard). read_command: 
<pre>
     read (0, buf, bufsize)
</pre>
<li>file descriptor 1 for output (e.g., terminal)
<pre>
     write (1, "hello\n", strlen("hello\n"))
</pre>
<li>file descriptor 2 for error (e.g., terminal)
</ul>
<li>on fork, child inherits open file descriptors from parent (show in
    process diagram).
<li>on exec, process retains file descriptors, except those specifically
    marked as close-on-exec: <code>fcntl(fd, F_SETFD, FD_CLOEXEC)</code>

<li>How does the shell implement:
<pre>
     $ ls > tmp1
</pre>
just before exec insert:
<pre>
	close(1);
	creat("tmp1", 0666);   // fd will be 1
</pre>
<p>The kernel always uses the first free file descriptor, 1 in this case.
    Could use <code>dup2()</code> to clone a file descriptor to a new number.

<li>Good illustration for why fork + exec vs. CreateProcess on Windows.
    (CreateProcess takes 10 arguments.)

<li>What if you run the shell itself with redirection?
<pre>
     $ sh < script > tmp1
</pre>
If for example the file <code>script</code> contains
<pre>
     echo one
     echo two
</pre>
FD inheritance makes this work well.

<li>What if we want to redirect multiple FDs (stdout, stderr)
    for programs that print to both?
<pre>
    $ ls f1 f2 nonexistant-f3 > tmp1 2> tmp1
</pre>
after creat, insert:
<pre>
	close(2);
	creat("tmp1", 0666);   // fd will be 2
</pre>
why is this bad?  illustrate what's going on with file descriptors.  better:
<pre>
	close(2);
	dup(1);		       // fd will be 2
</pre>
or in bourne shell syntax,
<pre>
    $ ls f1 f2 nonexistant-f3 > tmp1 2>&1
</pre>
Read Chapter 3 of <em>Advanced Programming in the UNIX Environment</em> by
W. Richard Stevens for a detailed understanding of how file descriptors
are implemented. In particular, read Section 3.10 to understand how
file sharing works.

<li>Linux has a nice representation of a process and its FDs, under /proc/PID/
<ul>
<li>maps: VA range, perms (p=private, s=shared), offset, dev, inode, pathname
<li>fd: symlinks to files pointed to by each fd.
    (what's missing in this representation?)
<li>can do fd manipulation in shell and see it reflected in /proc/$$/fd
</ul>

<li>how to run a series of programs on some data?
<pre>
	$ sort < file.txt > tmp1
	$ uniq tmp1 > tmp2
	$ wc tmp2
	$ rm tmp1 tmp2
</pre>
can be more concisely done as:
<pre>
        $ sort < file.txt | uniq | wc
</pre>
<li>A pipe is a one-way communication channel.  Here is a simple example:
<pre>
        int fdarray[2];
        char buf[512];
        int n;

        pipe(fdarray);
        write(fdarray[1], "hello", 5);
        n = read(fdarray[0], buf, sizeof(buf));
        // buf[] now contains 'h', 'e', 'l', 'l', 'o'
</pre>
<li>file descriptors are inherited across <code>fork()</code>, so this also works:
<pre>
        int fdarray[2];
        char buf[512];
        int n, pid;

        pipe(fdarray);
        pid = fork();
        if(pid > 0){
          write(fdarray[1], "hello", 5);
        } else {
          n = read(fdarray[0], buf, sizeof(buf));
        }
</pre>
<li>How does the shell implement pipelines (i.e., cmd 1 | cmd 2 |..)?
We want to arrange that the output of cmd 1 is the input of cmd 2.
The way to achieve this goal is to manipulate stdout and stdin.
<li>The shell creates processes for each command in
the pipeline, hooks up their stdin and stdout,
and waits for the last process of the
pipeline to exit.  Here's a sketch of what the shell does,
in the child process of the <code>fork()</code> we already have,
to set up a pipe:
<pre>	    
	    int fdarray[2];

  	    if (pipe(fdarray) < 0) panic ("error");
	    if ((pid = fork ()) == 0) {  child (left end of pipe)
	       close (1);
	       tmp = dup (fdarray[1]);   // fdarray[1] is the write end, tmp will be 1
	       close (fdarray[0]);       // close read end
	       close (fdarray[1]);       // close fdarray[1]
	       exec (command1, args1, 0);
	    } else if (pid > 0) {        // parent (right end of pipe)
	       close (0);
	       tmp = dup (fdarray[0]);   // fdarray[0] is the read end, tmp will be 0
	       close (fdarray[0]);
	       close (fdarray[1]);       // close write end
	       exec (command2, args2, 0);
	    } else {
	       printf ("Unable to fork\n");
            }
</pre>
<li>Who waits for whom? (draw a tree of processes)
<li>Why close read-end and write-end? ensure that
every process starts with 3 file descriptors, and that
reading from the pipe returns end of file after the first command exits.
<li>How do you create a background job?
<pre>
        $ compute &
</pre>
<li>How does the shell implement "&", backgrounding?  (Don't call wait
immediately).
</ul>

<h2>Threads</h2>

<p>Figure on process address space: code, static data, stack, heap. On
fork, the whole address space gets replicated. On thread create, the
created thread has a different program counter, registers, and stack (through
stack pointer). Everything else is shared between threads.

<p>Kernel-level threads are just processes minus separate address spaces.
Discuss the kernel scheduler which is invoked at every timer interrupt.
Each thread is an independent entity for the kernel.

<p>Write the <code>cswitch</code> function for processes and
threads. Notice that switching among threads requires no privileged
operations. Switching the stack can be done by switching the <code>sp</code>
register. A cswitch needs to be fast (typically a few 100 microseconds).

<p>Advantages of threads over processes
<ul>
<li> <em>Much</em> more lightweight than processes. Faster creation, deletion,
switching.
<li> Much faster communication among threads: allow shared data structures to
be maintained.
</ul>

<p>User-level threads can be implemented inside a process by writing
<code>scheduler()</code> and <code>cswitch()</code> functions. The
scheduler can be called periodically using SIGALRM signal.

<p>Pros of user-level threads:
<ul>
<li>Lighter-weight
<li>Faster cswitch
<li>Do not need kernel's permission
</ul>

<p>Cons of user-level threads:
<ul>
<li>Will not be scheduled on different cores, because they look like one
process to the kernel.
<li>If one thread blocks (e.g., on I/O), all threads block.
</ul>

<p>Threading models (slide)
  
<p>Thread pools (slide)

<h2>Concurrency and Synchronization</h2>
But if multiple threads share a memory location, good-looking
sequential programs can start failing.
e.g.,
shared static variable: <code>hits</code>
shared code: <code>hits = hits + 1</code>
Assume the shared code gets compiled into the following assembly
code
<pre>
  ld   [hits], R
	add  R, R, 1
  st   R, [hits]
</pre>
<code>hits</code> represents a memory location, and <code>[hits]</code>
represents the contents of that memory location. <code>ld [hits], R</code>
loads the contents of <code>hits</code> to register <code>R</code>.

<p>If two threads try and execute this code simultaneously what
can happen? Assume <code>hits=10</code> before starting these threads.
What interleavings cause <code>hits=12</code>? What interleavings
cause <code>hits=11</code>?

<p>This is a problem associated with <em>concurrent access to a shared
	data region</em>, in short <em>concurrency</em>. This is also called
a <em>race condition</em> (perhaps because it is a race between two
threads and the result depends on who wins).

<p>Concurrency could be "logical concurrency" on a single CPU due to
possibly arbitrary interruptions (or preemptions) caused by the
timer interrupt, or could be "physical concurrency" due to threads
executing simultaneously on different CPUs. The nature of the problem
in both cases is identical.

<p>Another example:
<pre>
  Thread A:
     i = 0;
     while (i < 10)
         i = i + 1;
     print "A won!";

  Thread B:
     i = 0;
     while (i > -10)
         i = i - 1;
     print "B won!";
</pre>
Who wins? Guaranteed that someone wins? What if both threads run on
identical speed CPU executing in parallel? (guaranteed to go on forever?)

<p>Another example
<pre>
    push(v):
        if (n == stack_size)
                return full;
        stack[n] = v;
        n = n + 1;
</pre>
Some bad schedules? Some that will work?

<p>One way to deal with the problem is to <em>enforce atomicity</em>
of certain code regions. In the <code>hits</code> example, we wanted
the three instructions to execute atomically with respect to themselves.
The code region that needs to be made atomic for the program
to be correct is also called the <em>critical section</em>.

<p>Locks are one way of implementing atomic regions. A lock <code>L</code>
is a shared variable that provides two methods <code>acquire(L)</code>
and <code>release(L)</code>. Any lock <code>L</code>
can be acquired by at most one thread at a time. Another thread
can acquire it only after it's holder has released it.
Any thread trying to acquire a lock which is already acquired by another
thread must wait for it to be released.

<p>Locks allow implementation of atomic regions by bracketing the
critical section using calls to <code>acquire()</code> and
<code>release</code>. For our <code>hits</code> example, the
new code will be:
<pre>
   lock hit_lock;    //shared lock.
   ...
   acquire(hit_lock);
   hit = hit + 1;
   release(hit_lock);
</pre>
What happens when one thread is inside the critical section and another
thread tries to enter it at the same time? What are the possible interleavings
now? Are all possible interleavings correct?
</body>


