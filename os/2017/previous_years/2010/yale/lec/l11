<html>
<head><title>Lecture 5</title>
</head>
<body>

<!--
    Notes for next time:
    - explicitly discuss aliasing and the fact that the same physical memory
      can show up multiple times in a virtual address space
    - context switching and why we have the kernel up at KERNBASE
      (maybe for the next lecture on interrupts, though)

  -->

<h2>Address translation and sharing using page tables</h2>

<p> Reading: <a href="../readings/i386/toc.htm">80386</a> chapters 5 and 6<br>

<p> Handout: <b> x86 address translation diagram</b> - 
<a href="x86_translation.pdf">PDF</a> -
<a href="x86_translation.svg">SVG</a>,
<b>JOS virtual memory layout</b> -
<a href="jos_layout.pdf">PDF</a> -
<a href="jos_layout.svg">SVG</a>
<br>

<p>Why do we care about x86 address translation?
<ul>
<li>It can simplify s/w structure: addresses in one process not constrained
    by what other processes might be running.
<li>It can implement tricks like demand paging and copy-on-write.
<li>It can isolate programs to contain bugs or increase security.
<li>It can provide efficient sharing between processes.
<li>JOS uses paging a lot, and segments more than you might think.
</ul>

<p>Why aren't protected-mode segments enough?
<ul>
<li>Why did the 386 add translation using page tables as well?
<li>Isn't it enough to give each process its own segments?
<li>Programming model, fragmentation
<li>In practice, segments are little-used
</ul>

<p>Translation using page tables (on x86):
<ul>
<li>segmentation hardware first computes the <emph>linear</emph> address
<li>in practice, most segments (e.g. in JOS, Linux) have base 0 and max limit,
    making the segmentation step a no-op.
<li>paging hardware then maps linear address (la) to physical address (pa)
<li>(we will often interchange "linear" and "virtual")
<li>when paging is enabled, every instruction that accesses memory is subject
    to translation by paging

<p>

<li>paging idea: break up memory into 4096-byte chunks called <emph>pages</emph>
<li>independently control mapping for each page of linear address space
<li>compare with segmentation (single base + limit): many more degrees of freedom

<p>

<li>4096-byte pages means there are 2^20 = 1,048,576 pages in 2^32 bytes
<li>conceptual model: array of 2^20 entries, called a <emph>page table</emph>,
    specifying the mapping for each linear page number
<li>table[20-bit linear page #] => 20-bit phys page #
<li>PTE entries: bottom of handout
<li>20-bit phys page number, present, read/write, user/supervisor, etc
<li>puzzle: can supervisor read/write user pages?

<p>

<li>can use paging hardware for many purposes
<ul>
    <li>(seen some of this two lectures ago)
    <li>flat memory
    <li>segment-like protection: contiguous mappings
    <li>solve fragmentation problems when allocating more memory (xv6-like process memory layout)
    <li>demand-paging (%cr2 stores faulting address)
    <li>copy-on-write
    <li>sharing, direct access to devices (e.g. /dev/fb on linux)
    <li>switching between processes
</ul>

<p>

<li>where is this table stored?  back in memory.
<li>in our conceptual model, CPU holds the physical address of the
    base of this table.
<li>%cr3 serves this purpose on the x86 (with one more detail below)
<li>for each memory access, access memory again to look up in table

<p>

<li>why not just have a big array with each page #'s translation?
<li>same problems that we were trying to solve with paging!
    (demand-paging, fragmentation)
<li>so, apply the same trick
<ul>
    <li>we broke up our 2^32-byte memory into 4096-byte chunks and
	represented them in a 2^22-byte (2^20-entry) table
    <li>now break up the 2^22-byte table into 4096-byte chunks too,
	and represent them in another 2^12-byte (2^10-entry) table
    <li>just another level of indirection
    <li>now all data structures are page-sized
</ul>

<li>386 uses 2-level mapping structure
<li>one page directory page, with 1024 page directory entries (PDEs)
<li>up to 1024 page table pages, each with 1024 page table entries (PTEs)

<li>so la has 10 bits of directory index, 10 bits table index, 12 bits offset
<li>%cr3 register holds physical address of current page directory
<li>puzzle: what do PDE read/write and user/supervisor flags mean?


<p>

<li>now, access memory twice more for every memory access: really expensive!
<li>optimization: CPU's TLB caches vpn => ppn mappings
<li>if you change any part of the page table, you must flush the TLB!
<ul>
    <li>by re-loading %cr3 (flushes everything)
    <li>by executing <code>invlpg <i>va</i></code>
</ul>

<p>

<li>turn on paging by setting CR0_PG bit of %cr0

<p>

<li>Here's how the MMU translates an la to a pa:

   <pre>
   uint
   translate (uint la, bool user, bool write)
   {
     uint pde; 
     pde = read_mem (%CR3 + 4*(la >> 22));
     access (pde, user, write);
     pte = read_mem ( (pde &amp; 0xfffff000) + 4*((la >> 12) &amp; 0x3ff));
     access (pte, user, write);
     return (pte &amp; 0xfffff000) + (la &amp; 0xfff);
   }

   // check protection. pxe is a pte or pde.
   // user is true if CPL==3
   void
   access (uint pxe, bool user, bool write)
   {
     if (!(pxe &amp; PG_P)  
        => page fault -- page not present
     if (!(pxe &amp; PG_U) &amp;&amp; user)
        => page fault -- not access for user
   
     if (write &amp;&amp; !(pxe &amp; PG_W)) {
       if (user)   
          => page fault -- not writable
       if (%CR0 &amp; CR0_WP) 
          => page fault -- not writable
     }
   }
   </pre>

</ul>


<p>Can we use paging to limit what memory an app can read/write?
<ul>
<li>user can't modify cr3 (requires privilege)
<li>is that enough?
<li>could user modify page tables? after all, they are in memory.
</ul>


<p>How we will use paging (and segments) in JOS:
<ul>
<li>use segments only to switch privilege level into/out of kernel
<li>use paging to structure process address space
<li>use paging to limit process memory access to its own address space
<li>below is the JOS virtual memory map
<li>why map both kernel and current process? why not 4GB for each?
    how does this compare with xv6?
<li>why is the kernel at the top?
<li>why map all of phys mem at the top? i.e. why multiple mappings?
<li>(will discuss UVPT in a moment...)
<li>how do we switch mappings for a different process?
</ul>

<pre>
    4 Gig -------->  +------------------------------+
                     |                              | RW/--
                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                     :              .               :
                     :              .               :
                     :              .               :
                     |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~| RW/--
                     |                              | RW/--
                     |   Remapped Physical Memory   | RW/--
                     |                              | RW/--
    KERNBASE ----->  +------------------------------+ 0xf0000000
                     |  Cur. Page Table (Kern. RW)  | RW/--  PTSIZE
    VPT,KSTACKTOP--> +------------------------------+ 0xefc00000      --+
                     |         Kernel Stack         | RW/--  KSTKSIZE   |
                     | - - - - - - - - - - - - - - -|                 PTSIZE
                     |      Invalid Memory          | --/--             |
    ULIM     ------> +------------------------------+ 0xef800000      --+
                     |  Cur. Page Table (User R-)   | R-/R-  PTSIZE
    UVPT      ---->  +------------------------------+ 0xef400000
                     |          RO PAGES            | R-/R-  PTSIZE
    UPAGES    ---->  +------------------------------+ 0xef000000
                     |           RO ENVS            | R-/R-  PTSIZE
 UTOP,UENVS ------>  +------------------------------+ 0xeec00000
 UXSTACKTOP -/       |     User Exception Stack     | RW/RW  PGSIZE
                     +------------------------------+ 0xeebff000
                     |       Empty Memory           | --/--  PGSIZE
    USTACKTOP  --->  +------------------------------+ 0xeebfe000
                     |      Normal User Stack       | RW/RW  PGSIZE
                     +------------------------------+ 0xeebfd000
                     |                              |
                     |                              |
                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                     .                              .
                     .                              .
                     .                              .
                     |~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|
                     |     Program Data &amp; Heap      |
    UTEXT -------->  +------------------------------+ 0x00800000
    PFTEMP ------->  |       Empty Memory           |        PTSIZE
                     |                              |
    UTEMP -------->  +------------------------------+ 0x00400000
                     |       Empty Memory           |        PTSIZE
    0 ------------>  +------------------------------+
</pre>


<h3>The UVPT</h3>

We had a nice conceptual model of the page table as a 2^20-entry array that
we could index with a physical page number.  The x86 2-level paging scheme
broke that, by fragmenting the giant page table into many page tables and
one page directory.  We'd like to get the giant conceptual page-table back
in some way -- processes in JOS are going to look at it to figure out
what's going on in their address space.  But how?

<p>Luckily, the paging hardware is great for precisely this -- putting
together a set of fragmented pages into a contiguous address space.
And it turns out we already have a table with pointers to all of our
fragmented page tables: it's the page directory!

<p>So, we can use the page <i>directory</i> as a page <i>table</i>
to map our conceptual giant 2^22-byte page table (represented by 1024
pages) at some contiguous 2^22-byte range in the virtual address space.
And we can ensure user processes can't modify their page tables by
marking the PDE entry as read-only.

<p>Puzzle: do we need to create a separate UVPD mapping too?

<hr>

A more detailed way of understanding this configuration:

<p>Remember how the X86 translates virtual addresses into physical ones:

<p><img src="pagetables.png">

<p>CR3 points at the page directory.  The PDX part of the address
indexes into the page directory to give you a page table.  The
PTX part indexes into the page table to give you a page, and then
you add the low bits in.

<p>But the processor has no concept of page directories, page tables,
and pages being anything other than plain memory.  So there's nothing
that says a particular page in memory can't serve as two or three of
these at once.  The processor just follows pointers:

pd = lcr3();
pt = *(pd+4*PDX);
page = *(pt+4*PTX);

<p>Diagramatically, it starts at CR3, follows three arrows, and then stops.

<p>If we put a pointer into the page directory that points back to itself at
index V, as in

<p><img src="vpt.png">

<p>then when we try to translate a virtual address with PDX and PTX
equal to V, following three arrows leaves us at the page directory.
So that virtual page translates to the page holding the page directory.
In Jos, V is 0x3BD, so the virtual address of the UVPD is
(0x3BD&lt;&lt;22)|(0x3BD&lt;&lt;12).

<p>Now, if we try to translate a virtual address with PDX = V but an
arbitrary PTX != V, then following three arrows from CR3 ends
one level up from usual (instead of two as in the last case),
which is to say in the page tables.  So the set of virtual pages
with PDX=V form a 4MB region whose page contents, as far
as the processor is concerned, are the page tables themselves.
In Jos, V is 0x3BD so the virtual address of the UVPT is (0x3BD&lt;&lt;22).

<p>So because of the "no-op" arrow we've cleverly inserted into
the page directory, we've mapped the pages being used as
the page directory and page table (which are normally virtually
invisible) into the virtual address space.

 
</body>
